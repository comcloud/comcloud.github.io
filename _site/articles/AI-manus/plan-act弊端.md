> “Plan → Act” 的两阶段流水线在演示时往往看起来很优雅，真正落到长期、多步、需要可靠性的场景里，最大的麻烦有下面这些：

1. **计划过时** 
   计划是一次性产物，后续执行过程中环境、需求、依赖随时会变，但 Agent 仍然按旧剧本走，导致越做越错。

   或者说在后续执行过程中就本身引入了不确定性，也就是执行也在改变环境

2. **错误级联** 
   一旦早期某一步执行结果偏离计划（哪怕只是微小偏差），后续步骤会基于错误前提继续执行，错误被层层放大，最终面目全非。

如果考虑**“加一个元认知模型全程监控”**
可以，但它同样面临 4 个难题：
a) 监控模型需要看到完整历史 → 上下文爆炸；
b) 它判断“偏离”需要标准 → 标准也得随需求一起变；
c) 它纠正时需要重写后续计划 → 等于再执行一次 Plan 阶段，成本高；
d) 如果纠正也出错，就产生“监控-被监控”级联失败。
所以“元认知”只是把单点 Plan-Act 变成了三层（Plan-Monitor-Act），没有消除根本矛盾。

3. **无反馈闭环** 
   计划阶段看不到真实执行结果，执行阶段又缺少实时回写机制，相当于“开环控制”。没有反馈就没有自我修正，只能祈祷初始计划 100 % 正确。

**“计划应该看得到执行结果，执行应该看得到计划”**
理论成立，实际落地时：
• 执行阶段输出的信息往往很长（完整 diff、日志、报错栈），一次性塞回 Plan 阶段会爆窗口；
• 如果只塞摘要，Plan 拿到的就是“有损信息”，无法判断细节是否仍一致；
• 于是要么频繁重跑 Plan（成本 × N），要么接受近似反馈（回到问题 2）。

4. **上下文窗口爆炸** 
   为了保证每一步都“对齐”原始计划，系统往往把整份计划 + 当前执行轨迹全部塞进 prompt，几步之后就触发窗口限制，必须做有损压缩，压缩又进一步加剧 1、2 问题。

5. **决策碎片化** 
   计划阶段和执行阶段由同一份 prompt 的不同段落驱动，但每一步的隐含决策（选库、命名、接口形式）并没有被显式记录和同步，容易出现前后不一致。

举例：
• 第 2 步决定“所有日期字段都叫 created_at”；
• 第 7 步写新表时 LLM 随手写成 create_time；
• 两处决策都藏在各自生成的代码里，没有集中记录；
• 结果数据库里出现两种字段名，后续查询全崩。
这些“小决策”散落在多步 prompt 里，很难被统一校验，所以叫碎片化。

6. **难以局部回滚** 
   发现第 N 步做错后，想只回滚到第 N-1 步并重新规划几乎做不到——要么整段历史一起丢掉（损失上下文），要么继续带着错误历史前行。

**“删掉当前这一步的上下文，从上一步重启”**
可以删，但：
• 第 N-1 步的 prompt 并不包含第 N 步生成的文件内容；
• 于是回滚后，LLM 重新生成的第 N 步可能跟删掉的那一步完全不同，甚至再次引入新的 bug；
• 如果第 N 步改动了公共库，第 N-1 步根本不知道这些改动，重启后会继续踩坑；
• 所以“回滚”不是简单地把对话历史截断，而是要**把文件系统、依赖状态、外部服务**一并回滚——这就超出了纯 prompt 工程范围，需要真正的“可逆执行环境”（容器快照、数据库迁移回滚、git reset --hard 等）。目前大多数 Agent 框架没有这么重的 infra。

一句话：Plan-Act 把“长期一致性”问题推迟到了执行期，而 LLM 的自回归特性决定了： 
**越靠后的步骤，越可能被早期的小偏差或窗口截断放大成灾难。** 
除非在每一步都插入“重新规划 + 状态同步”机制，但那本质上又把 Plan-Act 退化成了更细粒度的“边想边干”，与单线程逐步决策没有区别。

> 因此，Plan-Act 的致命伤不是“没有反馈”，而是**反馈信息太大、太杂、变化太快，以至于 LLM 在有限的上下文和推理预算里无法始终保持一致性**。