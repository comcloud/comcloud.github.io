1. **均方误差（MSE, Mean Squared Error）**：
   - 公式：\($\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$\)
   - 适用于回归问题，衡量预测值与真实值之间的平方差。
2. **平均绝对误差（MAE, Mean Absolute Error）**：
   - 公式：\($\frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$\)
   - 适用于回归问题，衡量预测值与真实值之间的绝对差。
3. **Huber损失（Huber Loss）**：
   - 公式：\($\frac{1}{n} \sum_{i=1}^{n} L_\ (y_i, \hat{y}_i)$\)
   - 其中 \($L_\ (y_i, \hat{y}_i) = \begin{cases} 
     \frac{1}{2} (y_i - \hat{y}_i)^2 & \text{if } |y_i - \hat{y}_i| \leq \ \\
     \ (|y_i - \hat{y}_i| - \frac{1}{2} ) & \text{otherwise} 
     \end{cases}$\)
   - 结合了MSE和MAE的优点，适用于回归问题，能够对异常值有较好的鲁棒性。
4. **Kullback-Leibler散度（KL Divergence）**：
   - 公式：\($\sum_{i=1}^{n} p(x_i) \log \frac{p(x_i)}{q(x_i)}$\)
   - 适用于衡量两个概率分布之间的差异，常用于生成模型和概率模型中。
5. **交叉熵损失（Cross-Entropy Loss）**：
   - 公式：\($-\sum_{i=1}^{n} y_i \log(\hat{y}_i)$\)
   - 适用于分类问题，尤其是二分类和多分类问题，用于衡量分类模型输出概率与真实标签的差异。
6. **对数损失（Log Loss）**：
   - 公式：\($-\frac{1}{n} \sum_{i=1}^{n} \left( y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right)$\)
   - 常用于二分类问题，类似于交叉熵损失，通常用于`Logistic`回归。
7. **对比损失（Contrastive Loss）**：
   - 适用于度量学习任务，用于衡量一对样本的相似度或不相似度。
8. **Triplet损失（Triplet Loss）**：
   - 适用于深度度量学习，用于训练模型在样本空间中区分正负样本。
