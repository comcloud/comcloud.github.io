<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>量化的核心原理</title>
  <meta name="description" content="深入讲解神经网络量化的数学原理、权重量化运算机制">
  <link rel="canonical" href="http://0.0.0.0:4000/blog/LLM/qwen/quantization-principles/">
  <link rel="alternate" type="application/rss+xml" title="成都犀牛 Feed"
    href="http://0.0.0.0:4000/feed.xml">
  
  <link rel="shortcut icon" href="/images/favicon.png" type="image/png" />
  
  <!-- Modern Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
  
  <!-- Styles -->
  <link href="/assets/css/temp-style.css" rel="stylesheet">
  
  <!-- Meta tags for better SEO and social sharing -->
  <meta property="og:title" content="量化的核心原理">
  <meta property="og:description" content="深入讲解神经网络量化的数学原理、权重量化运算机制">
  <meta property="og:type" content="website">
  <meta property="og:url" content="http://0.0.0.0:4000/blog/LLM/qwen/quantization-principles/">
  <meta name="twitter:card" content="summary_large_image">
</head>
<body>
  <!-- 页面加载动画 -->
  <div id="page-loader" class="page-loader">
    <div class="loader-content">
      <div class="cloud-container">
        <div class="cloud cloud-1"></div>
        <div class="cloud cloud-2"></div>
        <div class="cloud cloud-3"></div>
        <div class="cloud cloud-4"></div>
      </div>
      <div class="loader-text">
        <h2>云游君的小站</h2>
        <p>正在为您准备精彩内容...</p>
      </div>
      <div class="loading-progress">
        <div class="progress-bar"></div>
      </div>
    </div>
  </div>

  <div id="page" class="site page-hidden">
    <header class="site-header" id="site-header">
  <div class="container">
    
    <div class="site-title">
      <a href="/">
        成都犀牛
      </a>
    </div>
    
    
    <nav class="site-navigation" id="site-navigation">
      <div class="site-navigation-wrap">
        <ul class="menu">
          
          
          
          
            
            
            <li class="menu-item">
              <a href="/" class="">
                Home
              </a>
            </li>
          
            
            
            <li class="menu-item">
              <a href="/personal/" class="">
                Personal
              </a>
            </li>
          
            
            
            <li class="menu-item">
              <a href="/articles/" class="">
                Articles
              </a>
            </li>
          
            
            
            <li class="menu-item">
              <a href="https://github.com/comcloud" class="">
                comcloud
              </a>
            </li>
          
        </ul>
        <button id="menu-close" class="menu-toggle">
          <span class="visually-hidden">关闭菜单</span>
          ✕
        </button>
      </div>
    </nav>
    
    <button id="menu-open" class="menu-toggle">
      <span class="visually-hidden">打开菜单</span>
      ☰
    </button>
  </div>
</header>


    <main class="site-main">
      <main class="main-content fadeInDown delay_075s">
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">量化的核心原理</h1>
      
      <p class="post-description">深入讲解神经网络量化的数学原理、权重量化运算机制</p>
      
      
      <div class="post-meta">
        <time class="post-date">August 3, 2024</time>
      </div>
      
      
    </header><!-- .post-header -->
    
    <div class="post-content">
      <h3 id="量化的核心原理浮点数到整数的映射">量化的核心原理：浮点数到整数的映射</h3>

<p>量化的基本思想是将神经网络中通常使用的浮点数（如FP32，32位浮点数）表示的权重和激活值，映射到低位宽的整数（如INT8，8位整数）表示。这个映射过程需要定义一个<strong>量化函数</strong>和一个<strong>反量化函数</strong>。</p>

<p>最常见的量化方法是<strong>线性均匀量化 (Linear Uniform Quantization)</strong>，它通过一个<strong>缩放因子 (Scale Factor, \S)</strong> 和一个<strong>零点 (Zero Point, \Z)</strong> 来实现浮点数和整数之间的线性映射。</p>

<h4 id="1-量化参数-s-和-z-的确定">1. 量化参数 (<strong>S</strong> 和 <strong>Z</strong>) 的确定</h4>

<p>在进行量化之前，我们需要确定浮点数范围（$F_{min}$,$F_{max}$）和整数范围（$Q_{min}$,$Q_{max}$）。</p>

<ul>
  <li><strong>整数范围</strong>通常是固定的。例如，对于 8 位无符号整数<code class="highlighter-rouge"><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre> (UINT8)
</pre></td></tr></tbody></table></code>$Q_{min}=0$,$Q_{max}=255$；对于 8 位有符号整数 <code class="highlighter-rouge"><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>(INT8)
</pre></td></tr></tbody></table></code>，$Q_{min}=-128$,$Q_{max}=127$。</li>
  <li><strong>浮点数范围</strong>则需要从模型中获取。对于权重，可以通过其最小值和最大值直接确定。对于激活值，由于它们是动态变化的，通常需要在推理前通过<strong>校准 (Calibration)</strong> 过程，用一小部分代表性数据运行模型，收集激活值的统计信息（如最小值、最大值或均值、方差）来确定。</li>
</ul>

<p>一旦确定了浮点数的范围 ($F_{min}$,$F_{max}$） 和整数的范围 ($Q_{min}$,$Q_{max}$），就可以计算 S 和 Z：</p>

<ul>
  <li>
    <p>缩放因子 S (Scale Factor):
\(S=(Q_{max}−Q_{min})/ (F_{max}−F_{min})\)</p>

    <p>这个 S 表示浮点数单位的变化对应整数单位的变化量。</p>
  </li>
  <li>
    <p>零点 Z (Zero Point):</p>

    <p>Z=Qmin−SFmin</p>

    <p>零点 Z 是为了将浮点数 0.0 映射到某个整数值。它是一个整数，通过四舍五入得到。</p>
  </li>
</ul>

<h4 id="2-量化过程-quantization">2. 量化过程 (Quantization)</h4>

<p>将一个浮点数 FP 量化为整数 Q 的公式：</p>

<p>Q=round(SFP+Z)</p>

<p>其中 round 表示四舍五入。</p>

<h4 id="3-反量化过程-dequantization">3. 反量化过程 (Dequantization)</h4>

<p>在某些情况下，为了进行计算或输出，需要将整数 Q 反量化回浮点数 FPreconstructed。</p>

<p>FPreconstructed=(Q−Z)×S</p>

<p><strong>为什么需要零点 *<em>Z*</em>？</strong></p>

<p>零点的存在是为了确保浮点数 0.0 能够精确地映射到一个整数值（通常是 Qmin 或 Qmax 或中间某个值），这对于激活函数（如 ReLU，其中大量值为 0）和稀疏权重矩阵非常重要，可以避免量化误差累积。</p>

<h3 id="权重量化运算如何进行">权重量化运算如何进行？</h3>

<p>模型参数（权重）的量化比激活值相对简单，因为权重是固定的。主要有两种策略：</p>

<h4 id="1-离线量化-offline-quantization--ptq-post-training-quantization">1. 离线量化 (Offline Quantization) / PTQ (Post-Training Quantization)</h4>

<p>这是最常见的权重量化方式，特别是在部署阶段。</p>

<ol>
  <li>
    <p><strong>加载预训练的 FP32 模型。</strong></p>
  </li>
  <li>
    <p>逐层或逐通道地计算每个权重张量的 <strong>Fmin</strong> 和 <strong>Fmax</strong>。</p>

    <ul>
      <li>
        <p>例如，对于一个卷积核</p>

        <p>W∈RCout×Cin×KH×KW</p>

        <p>：</p>

        <ul>
          <li><strong>逐层量化：</strong> 找到整个 W 的最小值 Wmin 和最大值 Wmax。</li>
          <li><strong>逐通道量化：</strong> 对于每个输出通道 Cout，单独计算其对应权重的最小值和最大值，得到 Cout 组 (Sc,Zc)。这种方式精度通常更高。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>根据 *<em>Fmin,Fmax*</em> 和目标整数范围，计算出对应的 *<em>S*</em> 和 *<em>Z*</em>。</strong></p>
  </li>
  <li>
    <p><strong>使用 *<em>S*</em> 和 *<em>Z*</em> 将每个浮点权重 *<em>Wfp*</em> 量化为整数 *<em>Wq*</em>。</strong> Wq=round(SWfp+Z)</p>
  </li>
  <li>
    <p><strong>存储量化后的模型：</strong> 此时模型的权重都是 INT8 (或 INT4) 整数。</p>
  </li>
</ol>

<p><strong>推理时权重的运算：</strong></p>

<p>在推理时，量化后的权重 Wq 会直接参与计算。但在实际的硬件或推理引擎中，运算通常仍然是浮点运算（或者更精确地说是模拟浮点运算）。</p>

<p>考虑一个简单的乘法：Y=W×X</p>

<p>在量化后，变成：Yfp≈(Wq−Zw)×Sw×(Xq−Zx)×Sx</p>

<p>这个浮点乘法可以分解为整数运算：</p>

<p>Yfp≈(Wq⋅Xq−Wq⋅Zx−Xq⋅Zw+Zw⋅Zx)⋅Sw⋅Sx</p>

<p>为了避免频繁的反量化和浮点乘法，高性能的推理引擎（如 TensorRT）会进行<strong>算子融合 (Operator Fusion)</strong> 和<strong>整数化计算 (Integer-only Arithmetic)</strong>。它们会把 Sw⋅Sx 作为一个<strong>重标度因子 (rescale factor)</strong> 传递，并在中间结果中累积。最终的输出会在一个更高的整数精度（如 INT32）中进行累加，然后通过最终的缩放和零点转换为下一个 INT8 激活值或最终的 FP32 输出。</p>

<p><strong>核心思想是：</strong> 尽量在整数域内进行计算，只在必要时（如层与层之间传递激活值或最终输出）进行反量化和重新量化。</p>

<h4 id="2-在线量化-online-quantization--qat-quantization-aware-training">2. 在线量化 (Online Quantization) / QAT (Quantization-Aware Training)</h4>

<p>QAT 则是在训练过程中引入量化操作的模拟。</p>

<ol>
  <li>在训练图 (Computation Graph) 中插入伪量化 (Fake Quantization) 节点。
    <ul>
      <li>这些伪量化节点在正向传播时，会执行 <strong>量化 -&gt; 反量化</strong> 的操作。也就是说，浮点权重先被量化成低精度整数，然后立即反量化回浮点数。</li>
      <li>这样，模型在训练时，其浮点权重虽然仍然是 FP32，但它们会“感知”到低精度量化带来的误差，并学习如何去弥补这些误差。</li>
    </ul>
  </li>
  <li><strong>反向传播时，梯度仍然是针对 FP32 权重计算的。</strong> 伪量化操作通常是可导的（或者通过梯度旁路，Straight-Through Estimator, STE）。</li>
  <li><strong>训练结束后，直接保存模型中的 FP32 权重。</strong> 这些权重已经适应了量化误差。</li>
  <li><strong>在部署时，直接对这些训练好的 FP32 权重进行最终的量化</strong>（类似 PTQ 的步骤 2-4），将它们转换为 INT8。由于权重已经适应了量化，所以精度损失很小。</li>
</ol>

<p><strong>总结权重量化运算的原理：</strong></p>

<p>无论是 PTQ 还是 QAT，核心都是找到一个合适的线性映射关系（由 S 和 Z 定义），将原始浮点数范围映射到目标整数范围。在推理时，通过硬件支持的整数乘加指令，结合预先计算好的 S 和 Z，可以在整数域内高效地完成大部分计算，从而达到加速和减少资源占用的目的。对于大模型来说，由于其庞大的参数量，即使是 8-bit 或 4-bit 量化，也能带来巨大的内存和计算效益。</p>

    </div><!-- .post-content -->
    
    
    <footer class="post-footer">
      <div class="post-tags">
        <span class="tags-label">Tags:</span>
        
        <a href="/tags#qwen" class="tag-link">Qwen</a>, 
        
        <a href="/tags#%E9%87%8F%E5%8C%96" class="tag-link">量化</a>, 
        
        <a href="/tags#%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86" class="tag-link">数学原理</a>, 
        
        <a href="/tags#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" class="tag-link">深度学习</a>
        
      </div>
    </footer>
    
  </article><!-- .post -->
</main><!-- .site-main -->
    </main>
    <footer class="site-footer">
  <div class="offsite-links">
    
      
<a href="https://twitter.com/" target="_blank" rel="noopener">
  <span class="fa-twitter" aria-hidden="true"></span>
  <span class="screen-reader-text">Twitter</span>
</a>

<a href="https://github.com/" target="_blank" rel="noopener">
  <span class="fa-github" aria-hidden="true"></span>
  <span class="screen-reader-text">GitHub</span>
</a>

<a href="https://www.instagram.com/" target="_blank" rel="noopener">
  <span class="fa-instagram" aria-hidden="true"></span>
  <span class="screen-reader-text">Instagram</span>
</a>

<a href="https://www.linkedin.com/" target="_blank" rel="noopener">
  <span class="fa-linkedin" aria-hidden="true"></span>
  <span class="screen-reader-text">LinkedIn</span>
</a>

    
  </div><!-- .offsite-links -->
  <div class="footer-bottom">
    <div class="site-info">
      <p>© Scriptor all rights reserved. Theme by <a href="https://www.justgoodthemes.com">JustGoodThemes</a>.</p>

    </div><!-- .site-info -->
    <a href="#page" id="back-to-top" class="back-to-top"><span class="screen-reader-text">Back to the top </span>&#8593;</a>
  </div><!-- .footer-bottom -->
</footer><!-- .site-footer -->

  </div><!-- .site -->

  <!-- Scripts -->
  
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>
  
  <script src="/assets/js/plugins.js"></script>
  <script src="/assets/js/custom.js"></script>
  
  <!-- 移动端菜单脚本 -->
  <script>
    (function() {
      const menuOpen = document.getElementById('menu-open');
      const menuClose = document.getElementById('menu-close');
      const navigation = document.getElementById('site-navigation');
      const body = document.body;
      
      if (menuOpen && menuClose && navigation) {
        menuOpen.addEventListener('click', function() {
          navigation.classList.add('menu-open');
          body.classList.add('menu--opened');
        });
        
        menuClose.addEventListener('click', function() {
          navigation.classList.remove('menu-open');
          body.classList.remove('menu--opened');
        });
        
        // 点击导航外部区域关闭菜单
        navigation.addEventListener('click', function(e) {
          if (e.target === navigation) {
            navigation.classList.remove('menu-open');
            body.classList.remove('menu--opened');
          }
        });
      }
      
      // 头部滚动效果
      const header = document.getElementById('site-header');
      let lastScroll = 0;
      
      window.addEventListener('scroll', function() {
        const currentScroll = window.pageYOffset;
        
        if (currentScroll > 100) {
          header.classList.add('scrolled');
        } else {
          header.classList.remove('scrolled');
        }
        
        lastScroll = currentScroll;
      });
    })();
  </script>
  
  <!-- 加载动画脚本 -->
  <script>
    (function() {
      const loader = document.getElementById('page-loader');
      const site = document.getElementById('page');
      const progressBar = document.querySelector('.progress-bar');
      
      let progress = 0;
      const progressInterval = setInterval(() => {
        progress += Math.random() * 15;
        if (progress > 95) progress = 95;
        progressBar.style.width = progress + '%';
      }, 100);
      
      // 模拟加载进程，实际中可以基于资源加载情况
      window.addEventListener('load', function() {
        clearInterval(progressInterval);
        progressBar.style.width = '100%';
        
        setTimeout(function() {
          loader.classList.add('loader-hide');
          site.classList.remove('page-hidden');
          site.classList.add('page-show');
        }, 500);
        
        setTimeout(function() {
          loader.style.display = 'none';
        }, 1500);
      });
      
      // 防止加载时间过长，设置最大等待时间
      setTimeout(function() {
        if (loader && loader.style.display !== 'none') {
          clearInterval(progressInterval);
          progressBar.style.width = '100%';
          loader.classList.add('loader-hide');
          site.classList.remove('page-hidden');
          site.classList.add('page-show');
          
          setTimeout(function() {
            loader.style.display = 'none';
          }, 1000);
        }
      }, 3000);
    })();
  </script>

</body>
</html>