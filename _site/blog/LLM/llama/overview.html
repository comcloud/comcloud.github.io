<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Llama系列大模型全览：从Llama 1到Llama 4</title>
    <style>
        :root {
            --primary: #4267B2;
            --secondary: #898F9C;
            --accent: #00A6FF;
            --light: #F5F7FA;
            --dark: #1D2129;
            --success: #42B72A;
            --warning: #FFBA00;
            --danger: #FA3E3E;
            --radius: 8px;
            --shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            --transition: all 0.3s ease;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', 'PingFang SC', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            color: var(--dark);
            background-color: var(--light);
            overflow-x: hidden;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header Styles */
        header {
            background: linear-gradient(135deg, var(--primary), var(--accent));
            color: white;
            padding: 60px 0 80px;
            position: relative;
            overflow: hidden;
            text-align: center;
            margin-bottom: 60px;
        }

        header::before {
            content: "";
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" preserveAspectRatio="none"><path fill="rgba(255,255,255,0.05)" d="M0,0 L100,0 L100,100 L0,100 Z" /></svg>');
            background-size: cover;
            opacity: 0.3;
        }

        h1 {
            font-size: 2.8rem;
            margin-bottom: 20px;
            position: relative;
            animation: fadeInDown 1s ease;
        }

        .subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
            max-width: 800px;
            margin: 0 auto 30px;
            position: relative;
            animation: fadeIn 1.5s ease;
        }

        .scroll-down {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            color: white;
            font-size: 1.5rem;
            animation: bounce 2s infinite;
            cursor: pointer;
        }

        /* Navigation */
        .nav-container {
            position: sticky;
            top: 0;
            z-index: 100;
            background-color: rgba(255, 255, 255, 0.95);
            box-shadow: var(--shadow);
            backdrop-filter: blur(10px);
        }

        nav {
            display: flex;
            justify-content: center;
            padding: 15px 0;
        }

        nav a {
            color: var(--dark);
            text-decoration: none;
            margin: 0 15px;
            font-weight: 500;
            padding: 5px 10px;
            border-radius: var(--radius);
            transition: var(--transition);
            position: relative;
        }

        nav a:hover {
            color: var(--primary);
        }

        nav a::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 50%;
            width: 0;
            height: 2px;
            background: var(--primary);
            transition: var(--transition);
            transform: translateX(-50%);
        }

        nav a:hover::after {
            width: 100%;
        }

        /* Section Styles */
        section {
            padding: 60px 0;
            position: relative;
        }

        section:nth-child(even) {
            background-color: white;
        }

        h2 {
            font-size: 2.2rem;
            margin-bottom: 30px;
            color: var(--primary);
            position: relative;
            display: inline-block;
        }

        h2::after {
            content: '';
            position: absolute;
            bottom: -10px;
            left: 0;
            width: 60px;
            height: 4px;
            background: var(--accent);
            border-radius: 2px;
        }

        h3 {
            font-size: 1.6rem;
            margin: 30px 0 15px;
            color: var(--dark);
        }

        p {
            margin-bottom: 20px;
            font-size: 1.1rem;
            line-height: 1.8;
        }

        .highlight {
            background-color: rgba(66, 103, 178, 0.1);
            padding: 2px 5px;
            border-radius: 3px;
            font-weight: 500;
        }

        /* Table Styles */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 30px 0;
            box-shadow: var(--shadow);
            border-radius: var(--radius);
            overflow: hidden;
            animation: fadeInUp 1s ease;
        }

        th, td {
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid rgba(0, 0, 0, 0.05);
        }

        th {
            background-color: var(--primary);
            color: white;
            font-weight: 500;
        }

        tr:nth-child(even) {
            background-color: rgba(66, 103, 178, 0.05);
        }

        tr:hover {
            background-color: rgba(66, 103, 178, 0.1);
        }

        /* Card Styles */
        .card-container {
            display: flex;
            flex-wrap: wrap;
            gap: 30px;
            margin: 40px 0;
        }

        .card {
            flex: 1 1 300px;
            background: white;
            border-radius: var(--radius);
            box-shadow: var(--shadow);
            overflow: hidden;
            transition: var(--transition);
            position: relative;
        }

        .card:hover {
            transform: translateY(-10px);
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.15);
        }

        .card-header {
            background: var(--primary);
            color: white;
            padding: 15px 20px;
            font-weight: 500;
        }

        .card-body {
            padding: 20px;
        }

        .card-footer {
            padding: 15px 20px;
            background: rgba(0, 0, 0, 0.02);
            border-top: 1px solid rgba(0, 0, 0, 0.05);
        }

        /* Timeline Styles */
        .timeline {
            position: relative;
            max-width: 1000px;
            margin: 40px auto;
            padding: 0 20px;
        }

        .timeline::before {
            content: '';
            position: absolute;
            top: 0;
            bottom: 0;
            left: 50%;
            width: 4px;
            background: var(--primary);
            transform: translateX(-50%);
        }

        .timeline-item {
            position: relative;
            margin-bottom: 40px;
            width: 50%;
            padding: 20px;
            animation: fadeIn 1s ease;
        }

        .timeline-item:nth-child(odd) {
            left: 0;
        }

        .timeline-item:nth-child(even) {
            left: 50%;
        }

        .timeline-content {
            background: white;
            padding: 25px;
            border-radius: var(--radius);
            box-shadow: var(--shadow);
            position: relative;
        }

        .timeline-content::after {
            content: '';
            position: absolute;
            top: 20px;
            width: 20px;
            height: 20px;
            background: white;
            transform: rotate(45deg);
            box-shadow: 3px 3px 5px rgba(0, 0, 0, 0.1);
        }

        .timeline-item:nth-child(odd) .timeline-content::after {
            right: -10px;
        }

        .timeline-item:nth-child(even) .timeline-content::after {
            left: -10px;
        }

        .timeline-date {
            display: block;
            font-weight: 500;
            color: var(--accent);
            margin-bottom: 10px;
        }

        .timeline-item:nth-child(odd) {
            animation: slideInLeft 1s ease;
        }

        .timeline-item:nth-child(even) {
            animation: slideInRight 1s ease;
        }

        /* Footer */
        footer {
            background: var(--dark);
            color: white;
            padding: 40px 0;
            text-align: center;
        }

        .footer-content {
            max-width: 800px;
            margin: 0 auto;
        }

        .footer-links {
            display: flex;
            justify-content: center;
            margin: 20px 0;
        }

        .footer-links a {
            color: white;
            margin: 0 15px;
            text-decoration: none;
            transition: var(--transition);
        }

        .footer-links a:hover {
            color: var(--accent);
        }

        .copyright {
            opacity: 0.7;
            font-size: 0.9rem;
        }

        /* Animations */
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        @keyframes fadeInDown {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes slideInLeft {
            from {
                opacity: 0;
                transform: translateX(-50px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        @keyframes slideInRight {
            from {
                opacity: 0;
                transform: translateX(50px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        @keyframes bounce {
            0%, 20%, 50%, 80%, 100% {
                transform: translateY(0) translateX(-50%);
            }
            40% {
                transform: translateY(-20px) translateX(-50%);
            }
            60% {
                transform: translateY(-10px) translateX(-50%);
            }
        }

        /* Responsive Styles */
        @media (max-width: 768px) {
            h1 {
                font-size: 2.2rem;
            }

            h2 {
                font-size: 1.8rem;
            }

            .timeline::before {
                left: 30px;
            }

            .timeline-item {
                width: 100%;
                left: 0 !important;
                padding-left: 70px;
                padding-right: 0;
            }

            .timeline-item:nth-child(even) .timeline-content::after,
            .timeline-item:nth-child(odd) .timeline-content::after {
                left: 20px;
                right: auto;
            }

            nav {
                flex-wrap: wrap;
            }

            nav a {
                margin: 5px;
                font-size: 0.9rem;
            }
        }

        /* Floating Elements */
        .floating-llama {
            position: fixed;
            width: 100px;
            height: 100px;
            background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="%234267B2"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8zm-5.5-2.5l7.51-3.49L17.5 6.5 9.99 9.99 6.5 17.5zm5.5-6.6c.61 0 1.1.49 1.1 1.1s-.49 1.1-1.1 1.1-1.1-.49-1.1-1.1.49-1.1 1.1-1.1z"/></svg>');
            background-size: contain;
            background-repeat: no-repeat;
            opacity: 0.1;
            z-index: -1;
            animation: float 15s infinite ease-in-out;
        }

        @keyframes float {
            0%, 100% {
                transform: translate(0, 0) rotate(0deg);
            }
            25% {
                transform: translate(20px, 20px) rotate(5deg);
            }
            50% {
                transform: translate(0, 40px) rotate(0deg);
            }
            75% {
                transform: translate(-20px, 20px) rotate(-5deg);
            }
        }

        /* Back to Top Button */
        .back-to-top {
            position: fixed;
            bottom: 30px;
            right: 30px;
            width: 50px;
            height: 50px;
            background: var(--primary);
            color: white;
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            opacity: 0;
            visibility: hidden;
            transition: var(--transition);
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
            z-index: 99;
        }

        .back-to-top.active {
            opacity: 1;
            visibility: visible;
        }

        .back-to-top:hover {
            background: var(--accent);
            transform: translateY(-5px);
        }
    </style>
</head>
<body>
    <!-- Floating Background Elements -->
    <div class="floating-llama" style="top: 20%; left: 10%;"></div>
    <div class="floating-llama" style="top: 60%; left: 80%; animation-delay: 2s;"></div>
    <div class="floating-llama" style="top: 30%; left: 70%; animation-delay: 4s;"></div>
    <div class="floating-llama" style="top: 70%; left: 20%; animation-delay: 6s;"></div>

    <!-- Header -->
    <header>
        <div class="container">
            <h1>Llama系列大模型全览</h1>
            <p class="subtitle">从Llama 1到Llama 4的技术演进与应用分析</p>
        </div>
        <div class="scroll-down" onclick="scrollToContent()">↓</div>
    </header>

    <!-- Navigation -->
    <div class="nav-container">
        <nav>
            <a href="#overview">概述</a>
            <a href="#llama1-2">Llama 1 & 2</a>
            <a href="#llama3">Llama 3 & 3.1</a>
            <a href="#llama4">Llama 4</a>
            <a href="#conclusion">总结</a>
        </nav>
    </div>

    <!-- Main Content -->
    <div class="container">
        <!-- Overview Section -->
        <section id="overview">
            <h2>Llama系列发展概述</h2>
            <p>Meta的Llama系列大模型自2023年初首次亮相以来，已成为开源大语言模型领域最具影响力的产品线之一。这一系列模型以其<span class="highlight">高效架构</span>、<span class="highlight">开源策略</span>和<span class="highlight">持续创新</span>在学术界和工业界广受关注。</p>
            
            <p>从最初的Llama 1到最新发布的Llama 4，Meta通过不断迭代优化，逐步提升了模型在多语言处理、多模态理解和推理能力等方面的表现。</p>
            
            <table>
                <thead>
                    <tr>
                        <th>模型版本</th>
                        <th>发布时间</th>
                        <th>技术定位</th>
                        <th>主要创新</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Llama 1</td>
                        <td>2023年2月</td>
                        <td>基础语言模型</td>
                        <td>引入RMSNorm、SwiGLU激活函数和旋转位置嵌入(RoPE)</td>
                    </tr>
                    <tr>
                        <td>Llama 2</td>
                        <td>2023年7月</td>
                        <td>高性能开源模型</td>
                        <td>分组查询注意力(GQA)机制，完全开源支持商用</td>
                    </tr>
                    <tr>
                        <td>Llama 3</td>
                        <td>2024年4月</td>
                        <td>多语言/多任务模型</td>
                        <td>扩展词汇量，优化分词器，改进推理能力</td>
                    </tr>
                    <tr>
                        <td>Llama 3.1</td>
                        <td>2024年底</td>
                        <td>优化版本</td>
                        <td>优化训练数据质量，扩展上下文长度</td>
                    </tr>
                    <tr>
                        <td>Llama 4</td>
                        <td>2025年4月</td>
                        <td>多模态MoE模型</td>
                        <td>混合专家架构，原生多模态支持，超长上下文</td>
                    </tr>
                </tbody>
            </table>
            
            <p>Llama系列的成功不仅体现在技术层面，其<span class="highlight">开源策略</span>也极大地推动了AI应用的普及。自Llama 2起，Meta提供开源权重和代码，显著降低了中小企业的使用门槛。</p>
        </section>

        <!-- Llama 1 & 2 Section -->
        <section id="llama1-2">
            <h2>Llama 1与Llama 2：开源大模型的奠基之作</h2>
            
            <div class="timeline">
                <div class="timeline-item">
                    <div class="timeline-content">
                        <span class="timeline-date">2023年2月</span>
                        <h3>Llama 1发布</h3>
                        <p>作为Meta推出的首款开源大型语言模型，Llama 1基于Transformer解码器结构，引入了多项创新设计，包括<span class="highlight">RMSNorm层归一化</span>、<span class="highlight">SwiGLU激活函数</span>和<span class="highlight">旋转位置嵌入(RoPE)</span>。</p>
                        <p>Llama 1的开源特性打破了闭源模型的技术垄断，为研究社区提供了可自由使用的高质量语言模型基准。</p>
                    </div>
                </div>
                
                <div class="timeline-item">
                    <div class="timeline-content">
                        <span class="timeline-date">2023年7月</span>
                        <h3>Llama 2发布</h3>
                        <p>Llama 2引入了<span class="highlight">分组查询注意力(GQA)</span>机制，这一创新显著提升了大模型的训练效率，解决了传统多头注意力机制在参数量增大时面临的计算资源瓶颈问题。</p>
                        <p>Llama 2提供了7B和70B两种参数规模的版本，满足了不同应用场景的需求。其开源策略产生了深远影响，推动了AI应用的普及化进程。</p>
                    </div>
                </div>
            </div>
            
            <table>
                <thead>
                    <tr>
                        <th>技术特性</th>
                        <th>Llama 1</th>
                        <th>Llama 2</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>发布时间</td>
                        <td>2023年2月</td>
                        <td>2023年7月</td>
                    </tr>
                    <tr>
                        <td>架构基础</td>
                        <td>Transformer解码器</td>
                        <td>Transformer解码器+GQA</td>
                    </tr>
                    <tr>
                        <td>关键技术</td>
                        <td>RMSNorm, SwiGLU, RoPE</td>
                        <td>保留Llama1技术+分组查询注意力</td>
                    </tr>
                    <tr>
                        <td>开源程度</td>
                        <td>有限开源</td>
                        <td>完全开源，支持商用</td>
                    </tr>
                    <tr>
                        <td>参数规模</td>
                        <td>未公开详细数据</td>
                        <td>7B和70B两个版本</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <!-- Llama 3 Section -->
        <section id="llama3">
            <h2>Llama 3与3.1：多语言与多任务能力的飞跃</h2>
            
            <div class="card-container">
                <div class="card">
                    <div class="card-header">Llama 3</div>
                    <div class="card-body">
                        <p><strong>发布时间：</strong>2024年4月</p>
                        <p><strong>主要创新：</strong>扩展词汇量，优化分词器，改进推理能力</p>
                        <p><strong>多语言支持：</strong>显著提升</p>
                        <p><strong>上下文长度：</strong>优化处理机制</p>
                    </div>
                    <div class="card-footer">
                        <p>全球首个能与GPT-4对标的开源大模型</p>
                    </div>
                </div>
                
                <div class="card">
                    <div class="card-header">Llama 3.1</div>
                    <div class="card-body">
                        <p><strong>发布时间：</strong>2024年底</p>
                        <p><strong>主要创新：</strong>优化训练数据质量</p>
                        <p><strong>多语言支持：</strong>进一步扩展</p>
                        <p><strong>上下文长度：</strong>显著扩展</p>
                    </div>
                    <div class="card-footer">
                        <p>Llama 3的优化版本</p>
                    </div>
                </div>
            </div>
            
            <p>Llama 3的核心创新之一是其<span class="highlight">扩展的词汇量</span>和<span class="highlight">优化的分词器</span>，这使得模型能够支持更多语言，显著提升了多语言处理能力。与前代相比，Llama 3在非英语语言任务上的表现有了明显改善，为全球化应用奠定了基础。</p>
            
            <p>Llama 3.1作为Llama 3的优化版本，通过精细化的数据筛选和增强技术，提升了模型在特定任务上的表现，同时扩展了对更多语言的支持，进一步巩固了其作为多语言通用模型的地位。</p>
            
            <h3>应用与挑战</h3>
            <p>Llama 3系列在多个领域展现出强大潜力。在<span class="highlight">自然语言处理</span>方面，模型可用于对话系统、文本生成和情感分析等任务；在多模态领域，基于Llama 3.1的视觉语言模型已能够支持多页文档的视觉-文本分析。</p>
            
            <p>然而，Llama 3系列也面临一些<span class="highlight">争议和挑战</span>。据报道，Llama 3.1被发现能近乎完整复制受版权保护的书籍内容，引发了法律风险方面的担忧。同时，Meta使用"Books3"数据集训练模型的行为也面临多起版权诉讼。</p>
        </section>

        <!-- Llama 4 Section -->
        <section id="llama4">
            <h2>Llama 4：多模态MoE架构的革命性突破</h2>
            
            <p>Llama 4作为Meta于2025年4月推出的最新一代开源大模型，代表了当前开源多模态语言模型的技术巅峰。这一代模型首次全面采用<span class="highlight">混合专家架构(MoE)</span>，成为"第一个开源的主流多模态MoE大模型"。</p>
            
            <h3>混合专家架构(MoE)设计</h3>
            <p>Llama 4全面转向MoE架构，这与Llama 3坚持的密集模型(Dense Model)形成鲜明对比。MoE的核心思想是通过<span class="highlight">稀疏激活机制</span>，在大规模参数中仅激活部分"专家"来处理特定任务，从而在保持高性能的同时显著降低计算成本。</p>
            
            <p>Llama 4的MoE实现包含几个关键设计：</p>
            <ul style="margin-left: 20px; margin-bottom: 20px;">
                <li><strong>专家分布策略：</strong>小型模型(如Scout)采用较少专家(16个)，而大模型(如Maverick)使用更多专家(128个)，但总激活参数量保持稳定(170亿)。</li>
                <li><strong>动态路由机制：</strong>通过门控网络(Gating Network)根据输入特征选择激活哪些专家。</li>
                <li><strong>多模态专家分工：</strong>为不同模态(文本、图像等)设计了专用专家。</li>
            </ul>
            
            <table>
                <thead>
                    <tr>
                        <th>参数指标</th>
                        <th>Llama 4 Scout</th>
                        <th>Llama 4 Maverick</th>
                        <th>Llama 4 Behemoth</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>激活参数</td>
                        <td>170亿</td>
                        <td>170亿</td>
                        <td>2880亿(训练中)</td>
                    </tr>
                    <tr>
                        <td>总参数</td>
                        <td>1090亿</td>
                        <td>4000亿</td>
                        <td>2万亿(训练中)</td>
                    </tr>
                    <tr>
                        <td>专家数量</td>
                        <td>16个</td>
                        <td>128个</td>
                        <td>16个</td>
                    </tr>
                    <tr>
                        <td>上下文窗口</td>
                        <td>1000万token</td>
                        <td>256K token</td>
                        <td>未公布</td>
                    </tr>
                </tbody>
            </table>
            
            <h3>多模态实现机制</h3>
            <p>Llama 4的多模态能力建立在<span class="highlight">MetaCLIP</span>技术基础上，这是一种由Meta开发的先进语言-图像预训练模型。与OpenAI的CLIP不同，MetaCLIP不依赖复杂的架构调整，而是通过优化数据筛选和训练过程来提升性能。</p>
            
            <p>Llama 4的多模态处理采用了<span class="highlight">交错注意力层</span>设计，这一创新借鉴了Flamingo架构的思路。该技术通过交错self-attention和cross-attention来构建匹配感知编码器，能够同时学习图像本身的局部特征及其配对图像的相似性。</p>
            
            <h3>超长上下文支持技术</h3>
            <p>Llama 4 Scout版本支持高达<span class="highlight">1000万token</span>的上下文窗口，这一数字远超行业主流水平(如DeepSeek的128K)。实现这一突破的关键技术包括：</p>
            <ul style="margin-left: 20px; margin-bottom: 20px;">
                <li><strong>iRoPE扩展技术：</strong>推理时间温度缩放(Inference Time Temperature Scaling)</li>
                <li><strong>分层记忆结构：</strong>将上下文分为短期和长期记忆，动态管理token的存储和访问</li>
                <li><strong>数据压缩优化：</strong>通过更高效的分词器进一步压缩了输入表示</li>
            </ul>
        </section>

        <!-- Conclusion Section -->
        <section id="conclusion">
            <h2>总结与展望</h2>
            
            <p>从Llama 1到Llama 4的技术演进展现了开源大语言模型的快速发展轨迹。Meta通过持续创新和开放策略，成功打造了一个具有全球影响力的AI生态系统。</p>
            
            <p>Llama系列的成功经验表明：</p>
            <ul style="margin-left: 20px; margin-bottom: 20px;">
                <li><strong>开源策略</strong>是推动AI技术普及的关键因素</li>
                <li><strong>架构创新</strong>与<strong>计算效率</strong>的平衡至关重要</li>
                <li><strong>多模态能力</strong>将成为未来大模型的标准配置</li>
                <li><strong>混合专家架构</strong>代表了大规模模型的发展方向</li>
            </ul>
            
            <p>展望未来，Llama系列可能会在以下方向继续发展：</p>
            <ul style="margin-left: 20px; margin-bottom: 20px;">
                <li>更高效的训练和推理技术</li>
                <li>更强大的多模态理解和生成能力</li>
                <li>更完善的版权合规和数据安全机制</li>
                <li>更广泛的行业应用和生态系统建设</li>
            </ul>
            
            <p>随着Llama 4的发布和后续版本的开发，Meta有望继续保持在开源大模型领域的领导地位，同时推动整个AI行业向更加开放、高效和负责任的方向发展。</p>
        </section>
    </div>

    <!-- Footer -->
    <footer>
        <div class="footer-content">
            <h3>Llama系列大模型全览</h3>
            <p>从Llama 1到Llama 4的技术演进与应用分析</p>
            
            <div class="footer-links">
                <a href="#overview">概述</a>
                <a href="#llama1-2">Llama 1 & 2</a>
                <a href="#llama3">Llama 3</a>
                <a href="#llama4">Llama 4</a>
                <a href="#conclusion">总结</a>
            </div>
            
            <p class="copyright">© 2025 AI技术分析报告 | 基于Meta Llama系列公开资料整理</p>
        </div>
    </footer>

    <!-- Back to Top Button -->
    <div class="back-to-top" onclick="scrollToTop()">↑</div>

    <!-- JavaScript -->
    <script>
        // Scroll to content function
        function scrollToContent() {
            document.querySelector('#overview').scrollIntoView({
                behavior: 'smooth'
            });
        }

        // Back to top button
        window.addEventListener('scroll', function() {
            var backToTop = document.querySelector('.back-to-top');
            if (window.pageYOffset > 300) {
                backToTop.classList.add('active');
            } else {
                backToTop.classList.remove('active');
            }
        });

        function scrollToTop() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        }

        // Animate elements when they come into view
        const animateOnScroll = function() {
            const elements = document.querySelectorAll('.timeline-item, table, .card');
            
            elements.forEach(element => {
                const elementPosition = element.getBoundingClientRect().top;
                const windowHeight = window.innerHeight;
                
                if (elementPosition < windowHeight - 100) {
                    element.style.opacity = '1';
                    element.style.transform = 'translateY(0)';
                }
            });
        };

        // Set initial state for animated elements
        document.querySelectorAll('.timeline-item, table, .card').forEach(element => {
            element.style.opacity = '0';
            element.style.transition = 'opacity 0.6s ease, transform 0.6s ease';
            
            if (element.classList.contains('timeline-item:nth-child(odd)') || 
                element.classList.contains('card')) {
                element.style.transform = 'translateX(-30px)';
            } else if (element.classList.contains('timeline-item:nth-child(even)')) {
                element.style.transform = 'translateX(30px)';
            } else {
                element.style.transform = 'translateY(30px)';
            }
        });

        // Add scroll event listener
        window.addEventListener('scroll', animateOnScroll);
        
        // Run once on page load
        window.addEventListener('load', animateOnScroll);
    </script>
    <!-- 添加返回主页链接 -->
    <a href="../../" class="back-link">← 返回主页</a>
</body>
</html>